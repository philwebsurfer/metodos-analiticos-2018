{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen 2\n",
    "\n",
    "_ 175904 - Jorge III Altamirano Astorga_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import DataFrameStatFunctions, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://spark.apache.org/docs/latest/configuration.html\n",
    "conf = SparkConf()\n",
    "# conf.set(\"spark.driver.memory\", \"16g\")\n",
    "# conf.set(\"spark.driver.cores\", 4)\n",
    "# conf.set(\"spark.driver.memoryOverhead\", 0.9)\n",
    "# conf.set(\"spark.executor.memory\", \"32g\")\n",
    "# conf.set(\"spark.executor.cores\", 12)\n",
    "conf.set(\"spark.jars\", \"local:/home/jaa6766/spark-nlp_2.11-1.5.0.jar\")\n",
    "conf.set(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:1.5.0\")\n",
    "sc = SparkContext(master = \"spark://jupyter.corp.penoles.mx:7077\", \n",
    "                  sparkHome=\"/usr/local/spark/\",\n",
    "                  appName=\"examen-ma-2\", conf=conf)\n",
    "spark = SQLContext(sc)\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- cuisine: string (nullable = true)\n",
      " |-- ingredients: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "Show:\n",
      "+-----+-----------+--------------------+\n",
      "|   id|    cuisine|         ingredients|\n",
      "+-----+-----------+--------------------+\n",
      "|10259|      greek|[romaine lettuce,...|\n",
      "|25693|southern_us|[plain flour, gro...|\n",
      "|20130|   filipino|[eggs, pepper, sa...|\n",
      "|22213|     indian|[water, vegetable...|\n",
      "|13162|     indian|[black pepper, sh...|\n",
      "+-----+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 14.8 ms, sys: 8.25 ms, total: 23 ms\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "schema_ingredientes = schema=StructType().\\\n",
    "    add(\"id\", data_type=StringType(), nullable=False, metadata=None).\\\n",
    "    add(\"cuisine\", data_type=StringType(), nullable=False, metadata=None).\\\n",
    "    add(\"ingredients\", data_type=ArrayType(StringType()), nullable=True, metadata=None)\n",
    "train = spark.read.json(\"hdfs://jupyter.corp.penoles.mx:9000/ma2018-examen2/train.json\", \n",
    "                        schema=schema_ingredientes,\n",
    "                        allowUnquotedFieldNames=True,\n",
    "                        multiLine=True)\n",
    "print(\"Schema:\")\n",
    "train.printSchema()\n",
    "print(\"Show:\")\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conteo de Registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulación de la Columna\n",
    "\n",
    "Quitamos los arrays, para operar mejor el machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train\\\n",
    "    .withColumn(\"ingreds\", \n",
    "                col(\"ingredients\").cast(StringType()))\\\n",
    "    .withColumn(\"ingredientes\",\n",
    "               regexp_replace(col(\"ingreds\"), pattern=\"[\\[\\]]\", replacement=\"\"))\\\n",
    "    .select(\"id\", \"cuisine\", col(\"ingredientes\").alias(\"ingredients\"))\n",
    "train2.write.parquet(\"hdfs://jupyter.corp.penoles.mx:9000/ma2018-examen2/train2.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+\n",
      "|   id|    cuisine|         ingredients|\n",
      "+-----+-----------+--------------------+\n",
      "|10259|      greek|romaine lettuce, ...|\n",
      "|25693|southern_us|plain flour, grou...|\n",
      "|20130|   filipino|eggs, pepper, sal...|\n",
      "|22213|     indian|water, vegetable ...|\n",
      "|13162|     indian|black pepper, sha...|\n",
      "| 6602|   jamaican|plain flour, suga...|\n",
      "|42779|    spanish|olive oil, salt, ...|\n",
      "| 3735|    italian|sugar, pistachio ...|\n",
      "|16903|    mexican|olive oil, purple...|\n",
      "|12734|    italian|chopped tomatoes,...|\n",
      "| 5875|    italian|pimentos, sweet p...|\n",
      "|45887|    chinese|low sodium soy sa...|\n",
      "| 2698|    italian|Italian parsley l...|\n",
      "|41995|    mexican|ground cinnamon, ...|\n",
      "|31908|    italian|fresh parmesan ch...|\n",
      "|24717|     indian|tumeric, vegetabl...|\n",
      "|34466|    british|greek yogurt, lem...|\n",
      "| 1420|    italian|italian seasoning...|\n",
      "| 2941|       thai|sugar, hot chili,...|\n",
      "| 8152| vietnamese|soy sauce, vegeta...|\n",
      "+-----+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train2 = spark.read.parquet(\"hdfs://jupyter.corp.penoles.mx:9000/ma2018-examen2/train2.parquet\")\n",
    "train2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerías Spark NLP \n",
    "\n",
    "* <https://github.com/JohnSnowLabs/spark-nlp/issues/106>\n",
    "* <https://stackoverflow.com/questions/34302314/no-module-name-pyspark-error>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup sparknlp source\n",
    "## \n",
    "## https://github.com/JohnSnowLabs/spark-nlp/issues/106\n",
    "## https://stackoverflow.com/questions/34302314/no-module-name-pyspark-error\n",
    "import os, glob, sys\n",
    "sys.path.extend(glob.glob(\"/home/jaa6766/spark-nlp_2.11-1.5.0.jar\"))\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "import os, glob, sys\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.fpm import FPGrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- cuisine: string (nullable = true)\n",
      " |-- ingredients: string (nullable = true)\n",
      "\n",
      "showing results...\n",
      "+-----+-----------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id   |cuisine    |ingredients                                                                                                                        |\n",
      "+-----+-----------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|10259|greek      |romain@lettuc@,@black@oliv@,@grape@tomato@,@garlic@,@pepper@,@purpl@onion@,@season@,@garbanzo@bean@,@feta@chees@crumbl             |\n",
      "|25693|southern_us|plain@flour@,@ground@pepper@,@salt@,@tomato@,@ground@black@pepper@,@thym@,@egg@,@green@tomato@,@yellow@corn@meal@,@milk@,@veget@oil|\n",
      "+-----+-----------+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docAssemblr = DocumentAssembler()\\\n",
    "  .setInputCol(\"ingredients\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "tokenizr = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"tokens\")#    .addInfixPattern(\"(\\p{L}+)(n't\\b)\") \\\n",
    "    \n",
    "normalizr = Normalizer() \\\n",
    "    .setInputCols([\"tokens\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setPattern(\"[^A-Za-z,]\")\n",
    "    \n",
    "stemmr = Stemmer() \\\n",
    "  .setInputCols([\"normalized\"]) \\\n",
    "  .setOutputCol(\"stems\")\n",
    "    \n",
    "finishr = Finisher() \\\n",
    "    .setInputCols([\"stems\"]) \\\n",
    "    .setOutputCols([\"ingredients\"]) \\\n",
    "    .setIncludeKeys(False)\n",
    "\n",
    "pipeline = Pipeline(stages = [\n",
    "    docAssemblr,\n",
    "    tokenizr, \n",
    "    normalizr,\n",
    "    stemmr,\n",
    "    finishr\n",
    "])\n",
    "\n",
    "train.cache()\n",
    "model = pipeline.fit(train2)\n",
    "train3 = model.transform(train2)\n",
    "train3.printSchema()\n",
    "print(\"showing results...\")\n",
    "train3.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canastas\n",
    "\n",
    "En este primer paso lo que realizamos es volver a pasar los datos a array, para que sean canastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- cuisine: string (nullable = true)\n",
      " |-- ingredients: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+-----+-----------+--------------------+\n",
      "|   id|    cuisine|         ingredients|\n",
      "+-----+-----------+--------------------+\n",
      "|10259|      greek|[purpl@onion, bla...|\n",
      "|25693|southern_us|[veget@oil, salt,...|\n",
      "|20130|   filipino|[chicken@liver, g...|\n",
      "|22213|     indian|[water, veget@oil...|\n",
      "|13162|     indian|[water, cayenn@pe...|\n",
      "| 6602|   jamaican|[ground@ginger, f...|\n",
      "|42779|    spanish|[flat@leaf@parsle...|\n",
      "| 3735|    italian|[flour, white@alm...|\n",
      "|16903|    mexican|[iceberg@lettuc, ...|\n",
      "|12734|    italian|[flat@leaf@parsle...|\n",
      "| 5875|    italian|[mushroom, canola...|\n",
      "|45887|    chinese|[crush@red@pepper...|\n",
      "| 2698|    italian|[italian@parslei@...|\n",
      "|41995|    mexican|[avocado, crush@r...|\n",
      "|31908|    italian|[allpurpos@flour,...|\n",
      "|24717|     indian|[spinach, sweet@p...|\n",
      "|34466|    british|[confection@sugar...|\n",
      "| 1420|    italian|[italian@season, ...|\n",
      "| 2941|       thai|[asian@fish@sauc,...|\n",
      "| 8152| vietnamese|[veget@oil, chick...|\n",
      "+-----+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 42.6 ms, sys: 11.1 ms, total: 53.7 ms\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "udf_ingredients = udf(lambda ingredients: \n",
    "                      list(set(ingredients)), \n",
    "                      returnType=ArrayType(StringType()))\n",
    "train4 = train3 \\\n",
    "    .withColumn(\"ingredients\", regexp_replace(\"ingredients\", \"@?,@?\", \",\")) \\\n",
    "    .select(\"id\", \"cuisine\",\n",
    "        split(\"ingredients\", \"\\s*,\\s*\").alias(\"ingredients\")) \\\n",
    "    .cache() \\\n",
    "    .withColumn(\"ingredients\", udf_ingredients(\"ingredients\"))    \n",
    "#.select( \\\n",
    "#        \"id\",\n",
    "#        \"cuisine\",\n",
    "#        regexp_replace(\"ingredients\", \"\\@\", \"@ \").alias(\"ingredients\")\\\n",
    "#    ) \\\n",
    "train4.write.parquet(\"hdfs://jupyter.corp.penoles.mx:9000/ma2018-examen2/tmp-train4.parquet\", mode=\"overwrite\")\n",
    "train4 = spark.read.parquet(\"hdfs://jupyter.corp.penoles.mx:9000/ma2018-examen2/tmp-train4.parquet\")\n",
    "train4.printSchema()\n",
    "train4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 3.55 ms, total: 17.8 ms\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fp = FPGrowth(minSupport=0.1, minConfidence=0.2, itemsCol=\"ingredients\")\n",
    "fpm = fp.fit(train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|items                |freq |\n",
      "+---------------------+-----+\n",
      "|[salt]               |18048|\n",
      "|[onion]              |7972 |\n",
      "|[oliv@oil]           |7971 |\n",
      "|[water]              |7457 |\n",
      "|[garlic]             |7380 |\n",
      "|[sugar]              |6434 |\n",
      "|[garlic@clove]       |6236 |\n",
      "|[butter]             |4847 |\n",
      "|[ground@black@pepper]|4784 |\n",
      "|[allpurpos@flour]    |4632 |\n",
      "|[pepper]             |4438 |\n",
      "|[onion, salt]        |4392 |\n",
      "|[veget@oil]          |4385 |\n",
      "|[oliv@oil, salt]     |4177 |\n",
      "+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpm.freqItemsets.orderBy(col(\"freq\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reglas de Asociación y Predicciones\n",
    "\n",
    "Al parecer no se observan reglas de asociación. Por ende, no hay predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------+\n",
      "|antecedent|consequent|         confidence|\n",
      "+----------+----------+-------------------+\n",
      "|    [salt]|[oliv@oil]|0.23143838652482268|\n",
      "|    [salt]|   [onion]|0.24335106382978725|\n",
      "|[oliv@oil]|    [salt]| 0.5240245891356166|\n",
      "|   [onion]|    [salt]| 0.5509282488710486|\n",
      "+----------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpm.associationRules.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|id   |cuisine    |ingredients                                                                                                                                                                                                                               |prediction       |\n",
      "+-----+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|10259|greek      |[purpl@onion, black@oliv, season, romain@lettuc, pepper, garlic, feta@chees@crumbl, grape@tomato, garbanzo@bean]                                                                                                                          |[]               |\n",
      "|25693|southern_us|[veget@oil, salt, green@tomato, milk, tomato, thym, egg, yellow@corn@meal, ground@pepper, ground@black@pepper, plain@flour]                                                                                                               |[oliv@oil, onion]|\n",
      "|20130|filipino   |[chicken@liver, grill@chicken@breast, mayonais, salt, yellow@onion, cook@oil, pepper, egg, garlic@powder, soi@sauc, green@chili, butter]                                                                                                  |[oliv@oil, onion]|\n",
      "|22213|indian     |[water, veget@oil, salt, wheat]                                                                                                                                                                                                           |[oliv@oil, onion]|\n",
      "|13162|indian     |[water, cayenn@pepper, doubl@cream, black@pepper, boneless@chicken@skinless@thigh, lemon@juic, natur@yogurt, ground@cumin, chili@powder, garlic@past, milk, salt, bai@leaf, oil, passata, cornflour, shallot, butter, onion, garam@masala]|[oliv@oil]       |\n",
      "|6602 |jamaican   |[ground@ginger, fresh@ginger@root, sugar, salt, milk, egg, vanilla@extract, powder@sugar, plain@flour, butter, bake@powder, ground@cinnamon]                                                                                              |[oliv@oil, onion]|\n",
      "|42779|spanish    |[flat@leaf@parslei, skirt@steak, medium@shrimp, oliv@oil, white@vinegar, salt, bai@leaf, pepper, garlic, chop@cilantro, jalapeno@chili, sea@salt, chorizo@sausag]                                                                         |[onion]          |\n",
      "|3735 |italian    |[flour, white@almond@bark, almond@extract, pistachio@nut, sugar, oliv@oil, egg, vanilla@extract, dri@cranberri, bake@powder]                                                                                                              |[salt]           |\n",
      "|16903|mexican    |[iceberg@lettuc, cheddar@chees, purpl@onion, oliv@oil, lime, salt, fresh@pineappl, corn@tortilla, jalapeno@chili, poblano@pepper, ground@black@pepper, pork, chop@cilantro@fresh]                                                         |[onion]          |\n",
      "|12734|italian    |[flat@leaf@parslei, kosher@salt, fresh@basil, extravirgin@oliv@oil, garlic, chop@tomato]                                                                                                                                                  |[]               |\n",
      "+-----+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpm.transform(train4).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos con ingredientes arbitrarios\n",
    "* **Salt**, Eggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+\n",
      "| ingredients|       prediction|\n",
      "+------------+-----------------+\n",
      "|[salt, eggs]|[oliv@oil, onion]|\n",
      "+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpm.transform(spark.createDataFrame([([\"salt\", \"eggs\"], )], [\"ingredients\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['old@el@paso@mild@red@enchilada@sauc',\n",
       " 'cook@chicken',\n",
       " 'mexican@chees@blend',\n",
       " 'pillsburi@refriger@crescent@dinner@roll',\n",
       " 'red@enchilada@sauc',\n",
       " 'refriger@crescent@roll']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "spark.registerDataFrameAsTable(train3, \"train3\")\n",
    "spark.registerDataFrameAsTable(train4, \"train4\")\n",
    "ingredients_nonunique = spark\\\n",
    "    .sql(\"SELECT ingredients FROM train4 WHERE id = 1667 OR \\\n",
    "         array_contains(ingredients, 'old@ el@ paso@ mild@ red@ enchilada@ sauc@ ')\") \\\n",
    "    .collect()[0].ingredients\n",
    "ingredients_nonunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lettuce, Tomato, **Olive@oil**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----------+\n",
      "|ingredients                |prediction|\n",
      "+---------------------------+----------+\n",
      "|[lettuce, tomato, oliv@oil]|[salt]    |\n",
      "+---------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpm.transform(spark.createDataFrame([([\"lettuce\", \"tomato\", \"oliv@oil\"], )], [\"ingredients\"])).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.24 ms, sys: 2.41 ms, total: 9.65 ms\n",
      "Wall time: 2.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6681"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train4.select(explode(\"ingredients\")).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import NorvigSweetingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method JavaParams.__del__ of NorvigSweetingModel_4412ab6c985cb6aeb72c>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/intel/intelpython3/lib/python3.6/site-packages/pyspark/ml/wrapper.py\", line 105, in __del__\n",
      "    SparkContext._active_spark_context._gateway.detach(self._java_obj)\n",
      "  File \"/opt/intel/intelpython3/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1897, in detach\n",
      "    java_object._detach()\n",
      "AttributeError: 'NoneType' object has no attribute '_detach'\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2273.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 65.0 failed 4 times, most recent failure: Lost task 0.3 in stage 65.0 (TID 330, 10.10.208.210, executor 0): java.lang.NoClassDefFoundError: Lcom/typesafe/config/Config;\n\tat java.lang.Class.getDeclaredFields0(Native Method)\n\tat java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n\tat java.lang.Class.getDeclaredField(Class.java:2068)\n\tat java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n\tat java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n\tat java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1875)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1744)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2032)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:1965)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1560)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: com.typesafe.config.Config\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 80 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3272)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3253)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3252)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.GeneratedMethodAccessor78.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NoClassDefFoundError: Lcom/typesafe/config/Config;\n\tat java.lang.Class.getDeclaredFields0(Native Method)\n\tat java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n\tat java.lang.Class.getDeclaredField(Class.java:2068)\n\tat java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n\tat java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n\tat java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1875)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1744)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2032)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:1965)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1560)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.ClassNotFoundException: com.typesafe.config.Config\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 80 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-1cc2cee8e1ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrain4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/intel/intelpython3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/intel/intelpython3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/intel/intelpython3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/intel/intelpython3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2273.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 65.0 failed 4 times, most recent failure: Lost task 0.3 in stage 65.0 (TID 330, 10.10.208.210, executor 0): java.lang.NoClassDefFoundError: Lcom/typesafe/config/Config;\n\tat java.lang.Class.getDeclaredFields0(Native Method)\n\tat java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n\tat java.lang.Class.getDeclaredField(Class.java:2068)\n\tat java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n\tat java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n\tat java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1875)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1744)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2032)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:1965)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1560)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: com.typesafe.config.Config\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 80 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3272)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3253)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3252)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.GeneratedMethodAccessor78.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NoClassDefFoundError: Lcom/typesafe/config/Config;\n\tat java.lang.Class.getDeclaredFields0(Native Method)\n\tat java.lang.Class.privateGetDeclaredFields(Class.java:2583)\n\tat java.lang.Class.getDeclaredField(Class.java:2068)\n\tat java.io.ObjectStreamClass.getDeclaredSUID(ObjectStreamClass.java:1803)\n\tat java.io.ObjectStreamClass.access$700(ObjectStreamClass.java:79)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:494)\n\tat java.io.ObjectStreamClass$2.run(ObjectStreamClass.java:482)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat java.io.ObjectStreamClass.<init>(ObjectStreamClass.java:482)\n\tat java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:379)\n\tat java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:669)\n\tat java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1875)\n\tat java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1744)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2032)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:1965)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1560)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:479)\n\tat sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1158)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2168)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2277)\n\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2201)\n\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2059)\n\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1566)\n\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:426)\n\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)\n\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:80)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.ClassNotFoundException: com.typesafe.config.Config\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 80 more\n"
     ]
    }
   ],
   "source": [
    "norvig = NorvigSweetingModel().pretrained(name=\"spell_fast\", language=\"en\")\n",
    "norvig.setInputCols([\"tokens\"])\n",
    "norvig.setOutputCol(\"ingredients2\")\n",
    "pipeline1 = Pipeline(stages = [\n",
    "    docAssemblr,\n",
    "    tokenizr, \n",
    "    norvig\n",
    "#     normalizr,\n",
    "#     stemmr,\n",
    "#     finishr\n",
    "])\n",
    "model1 = pipeline1.fit(train2)\n",
    "train4 = model1.transform(train2)\n",
    "train4.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin del Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "\n",
    "* [Notas del Curso Métodos Analíticos, Luis Felipe González, ITAM Primavera 2018](https://clever-mestorf-ee3f54.netlify.com)\n",
    "* <https://github.com/JohnSnowLabs/spark-nlp/blob/master/python/example/model-downloader/ModelDownloaderExample.ipynb>\n",
    "* <https://nlp.johnsnowlabs.com/components.html>\n",
    "* <https://nlp.johnsnowlabs.com/notebooks.html>\n",
    "* <https://github.com/JohnSnowLabs/spark-nlp/blob/1.5.0/python/example/vivekn-sentiment/sentiment.ipynb>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

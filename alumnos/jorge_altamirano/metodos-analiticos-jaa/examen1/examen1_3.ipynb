{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen 1 - Parte 3\n",
    "\n",
    "_175904 - Jorge III Altamirano Astorga_\n",
    "\n",
    "_177508 - Uriel Miranda Miñón_\n",
    "\n",
    "## Sección pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import DataFrameStatFunctions, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f0980a83c50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://spark.apache.org/docs/latest/configuration.html\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"16g\")\n",
    "conf.set(\"spark.driver.cores\", 4)\n",
    "conf.set(\"spark.driver.memoryOverhead\", 0.9)\n",
    "conf.set(\"spark.executor.memory\", \"32g\")\n",
    "conf.set(\"spark.executor.cores\", 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(master = \"local\", sparkHome=\"/usr/local/spark/\", \n",
    "                  appName=\"examen-ma-1-3\", conf=conf)\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = sql.read.csv(\"movielens/ratings.csv\", header=True, inferSchema=True)\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "+------+---------+\n",
      "|userId|timestamp|\n",
      "+------+---------+\n",
      "| 28507|789652004|\n",
      "|131160|789652009|\n",
      "|131160|789652009|\n",
      "|131160|789652009|\n",
      "| 20821|822873600|\n",
      "+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_hll = ratings.select(\"userId\", \"timestamp\").\\\n",
    "    orderBy(col(\"timestamp\")).limit(1000000)\n",
    "ratings_hll.printSchema()\n",
    "ratings_hll.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteo Probabilístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Conteo_Aprox|\n",
      "+------------+\n",
      "|       16262|\n",
      "+------------+\n",
      "\n",
      "Tiempo que tomó el cálculo: 47 segundos\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ratings_hll.select(approxCountDistinct(\"userId\", rsd=0.05).alias(\"Conteo_Aprox\")).show()\n",
    "end = time.time()\n",
    "print(\"Tiempo que tomó el cálculo: %d segundos\"% (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo que tomó el cálculo: 41 segundos\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "ratings_hll.approxQuantile(\"userId\", [0.1, 0.5, 0.9], 0.05)\n",
    "end = time.time()\n",
    "print(\"Tiempo que tomó el cálculo: %d segundos\"% (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "* <https://databricks.com/blog/2016/05/19/approximate-algorithms-in-apache-spark-hyperloglog-and-quantiles.html>\n",
    "* [PySpark Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_Cheat_Sheet_Python.pdf)\n",
    "* <https://blog.insightdatascience.com/using-jupyter-on-apache-spark-step-by-step-with-a-terabyte-of-reddit-data-ef4d6c13959a>\n",
    "* <https://spark.apache.org/docs/1.6.1/sql-programming-guide.html>\n",
    "* <https://stackoverflow.com/questions/45287832/pyspark-approxquantile-function>\n",
    "* [Holden Karau, Rachel Warren. June 2017. _High Performance Spark_: O'Reilly Media](http://liuchengxu.org/books/src/Spark/High-Performance-Spark.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

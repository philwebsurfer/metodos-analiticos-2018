---
title: "Examen 1 - Ejercicio 2"
output:
  html_document:
    df_print: paged
---

_175904 - Jorge III Altamirano Astorga_

_177508 - Uriel Miranda Miñón_

```{r include=FALSE}
library(Rcpp)
library(Matrix)
library(tidyverse)
library(sparklyr)
```

# {.tabset}

## Carga de Datos

```{r}
set.seed(28882)
Rcpp::sourceCpp('../../../../src/factorizacion_mat/descenso_estocastico.cpp')
Rcpp::sourceCpp('../../../../src/factorizacion_mat/calc_error_bias.cpp')
recm <- function(calif, pred){
  sqrt(mean((calif - pred)^2))
}
muestra_nf <- read_csv('movielens/ratings.csv', progress = F,
                          col_names = TRUE, na = c("", "NA", "NULL"));
pelis_nombres <- read_csv('movielens/movies.csv',  progress = F,
                          col_names = TRUE, na = c("", "NA", "NULL"));
names(pelis_nombres) <- c('peli_id','nombre')
names(muestra_nf) <- c('usuario_id_orig','peli_id','calif','timestamp')
head(pelis_nombres)
```

```{r}
muestra_nf <- muestra_nf %>% 
  mutate(usuario_id = as.integer(as.factor(usuario_id_orig)))
dim(muestra_nf)
```


```{r}
head(muestra_nf)
```

## Entrenamiento y Validación

Construye una muestra de entrenamiento y una de validación:

Se considera el 20 % de los usuarios ya que con mayor cantidad de datos no es posible hacer la carga a Spark.

Una vez considerado el 20% de los usuarios, se separa en un 25% de usuarios para validación y el resto para entrenamiento.

```{r}
set.seed(28882)
frac <- trunc((max(muestra_nf$usuario_id)*1.0),0)
muestra_nf <- muestra_nf[1:sum(muestra_nf$usuario_id<=frac),]
valida_usuarios <- sample(unique(muestra_nf$usuario_id),  max(unique(muestra_nf$usuario_id))*.25)
valida_pelis <- sample(unique(muestra_nf$peli_id), 2000)
dat_2 <- muestra_nf %>%
  mutate(valida_usu = usuario_id %in% valida_usuarios) %>%
  mutate(valida_peli = peli_id %in% valida_pelis)

dif_movies <- unique(dat_2$peli_id)
# En validación van aquellas evaluaciones de las películas y
# usuario que seleccionamos
dat_valida <- filter(dat_2, valida_usu & valida_peli)
# En entrenamiento va el resto: algunas evaluaciones de usuarios
# seleccionados van en entrenamiento, por ejemplo (para películas
# no seleccionadas en validación)
dat_entrena <- filter(dat_2, !valida_usu | !valida_peli)

nrow(dat_entrena) + nrow(dat_valida)
```

```{r}
# rm(list = c('muestra_nf','muestra_nf'))
```


```{r}
# configuración para spark
config <- spark_config()
config$`sparklyr.shell.driver-memory` <- "48G"
config$sparklyr.cores.local <- 4
config$spark.memory.fraction <- 0.9
sc <- spark_connect(master="local",
              # version = "2.1.0",
              config = config,
              spark_home = "/home/rstudio/.cache/spark/spark-2.2.0-bin-hadoop2.7")
spark_set_checkpoint_dir(sc, './checkpoint')
```

```{r}
sc <- spark_connect(master = "local", config = config)
```


```{r}
spark_set_checkpoint_dir(sc, './checkpoint')
```


```{r}
media_gral_ent <- mean(dat_entrena$calif)
dat <- dat_entrena %>% 
      as_data_frame %>% 
      select(peli_id, usuario_id, calif)
dat_tbl <- copy_to(sc, dat, overwrite = TRUE)
```

## Descenso Estocástico

Utiliza descenso estocástico o mínimos cuadrados alternados para encontrar factores latentes.

Se utiliza el método de mínimos cuadrados con 8 factores latentes.

```{r}
modelo <- ml_als(dat_tbl, 
              rating_col = 'calif',
              user_col = 'usuario_id',
              item_col = 'peli_id', 
              rank = 8, reg_param = 0.05,
              checkpoint_interval = 5,
              max_iter = 30)
```


```{r}
valida_tbl <- copy_to(sc, dat_valida)
preds <- sdf_predict(valida_tbl, modelo) %>% collect() #traemos a R con collect
```

```{r}
ggplot(preds, aes(x = prediction)) + geom_histogram()
```

## Factores Latentes

Evalúa el modelo de factores latentes que ajustaste usando la muestra de validación y ajusta parámetros si es necesario para mejorar el desempeño.


La evaluación muestra un desempeño de 79% con los ajustes realizados.

```{r}
preds$prediction[is.nan(preds$prediction)] <- media_gral_ent
preds %>% ungroup %>% summarise(error = recm(calif, prediction))
```


```{r}
V_df <- collect(modelo$item_factors)
dim(V_df)
head(dat_2)
```

Explica cómo hacer predicciones a partir del modelo (predicción de la calificación 1-5). ¿Qué películas recomendarías para el usuario usuario 4000 y el usuario 6000, y usuario 1333? (que no haya visto).

El sistema puede proponer calificaciones para un usuario con base en las calificaciones que posee; por esa razón debemos  ingresar al modelo las películas que no ha calificado el usuario para saber el pronóstico de calificaciones. Con esa información podremos ordenar y por tanto recomendar aquellas que tengan el pronóstico mas alto.

```{r}
pred_usuario <- function(user){
  usr_predic <- dif_movies[!((filter(dat_2,usuario_id ==user)$peli_id) == dif_movies)]
  us <- data_frame(usuario_id = rep(user,length(usr_predic)), peli_id =usr_predic)
  us_sc <- copy_to(sc, us, overwrite=TRUE)
  us_pr <-sdf_predict(us_sc, modelo) %>% collect()
  us_recom<- us_pr[order(us_pr$prediction,decreasing = TRUE),] %>% head %>% left_join(pelis_nombres) %>% select (usuario_id,nombre)
  us_recom
}
```


```{r}
pred_usuario(4000)
```

```{r}
pred_usuario(6000)
```

```{r}
pred_usuario(1333)
```

```{r}
sparklyr::spark_disconnect_all()
```

## Examen

1. Construye una muestra de entrenamiento y una de validación

_Se muestra en la sección "Entrenamiento y Validación"._

2. Utiliza descenso estocástico o mínimos cuadrados alternados para encontrar factores latentes.

_Se muestra en la sección "Descenso Estocástico"._

3. Evalúa el modelo de factores latentes que ajustaste usando la muestra de validación y ajusta parámetros si es necesario para mejorar el desempeño.

_Se muestra en la sección "Factores Latentes"._

4. Explica cómo hacer predicciones a partir del modelo (predicción de la calificación 1-5). ¿Qué películas recomendarías para el usuario usuario 4000 y el usuario 6000, y usuario 1333? (que no haya visto).

_El sistema puede proponer calificaciones para un usuario con base en las calificaciones que posee; por esa razón debemos  ingresar al modelo las películas que no ha calificado el usuario para saber el pronóstico de calificaciones. Con esa información podremos ordenar y por tanto recomendar aquellas que tengan el pronóstico mas alto._

Nota: si tienes problemas de memoria, por ejemplo, piensa en estrategias para resolverlo. Puedes correrlo en una máquina más grande, o intentar muestrar una fracción relativamente grande de usuarios.

_Intentamos utilizar un equipo con 64 GB de RAM sin éxito, por eso utilizamos el 20% de los datos._
